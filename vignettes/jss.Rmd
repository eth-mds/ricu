---
title:
  plain: "ricu: R's Interface to Intensive Care Data"
  formatted: "\\pkg{ricu}: \\proglang{R}'s Interface to Intensive Care Data"
  short: "\\pkg{ricu}: R meets ICU data"
author:
  - name: "Nicolas Bennett\\footnotemark[1]"
    affiliation: ETH Zürich
    address: |
      | Seminar for Statistics
      | Rämistrasse 101
      | CH-8092 Zurich
    email: \email{nicolas.bennett@stat.math.ethz.ch}
  - name: "Drago Plečko\\footnotemark[1]\\footnotetext[1]{These authors contributed equally.}"
    affiliation: ETH Zürich
    address: |
      | Seminar for Statistics
      | Rämistrasse 101
      | CH-8092 Zürich
    email: \email{drago.plecko@stat.math.ethz.ch}
  - name: Ida-Fong Ukor
    affiliation: "Monash Health \\AND"
    affiliation2: Monash Health
    address: |
      | Department of Anaesthesiology and Perioperative Medicine
      | 246 Clayton Road
      | Clayton VIC 3168
    email: \email{ida-fong.ukor@monashhealth.org}
  - name: Nicolai Meinshausen
    affiliation: ETH Zürich
    address: |
      | Seminar for Statistics
      | Rämistrasse 101
      | CH-8092 Zürich
    email: \email{meinshausen@stat.math.ethz.ch}
  - name: Peter Bühlmann
    affiliation: ETH Zürich
    address: |
      | Seminar for Statistics
      | Rämistrasse 101
      | CH-8092 Zürich
    email: \email{peter.buehlmann@stat.math.ethz.ch}
abstract: >
  Providing computational infrastructure for handling diverse intensive care unit (ICU) datasets, the \proglang{R} package \pkg{ricu} enables writing dataset-agnostic analysis code, thereby facilitating multi-center training and validation of machine learning models. The package is designed with an emphasis on extensibility both to new datasets as well as clinical data concepts, and currently supports the loading of around 100 patient variables corresponding to a total of 319,402 ICU admissions from 4 data sources collected in Europe and the United States. By allowing for the addition of user-specified medical concepts and data sources the aim of \pkg{ricu} is to foster robust, data-based intensive care research, allowing the user to externally validate their method or conclusion with relative ease, and in turn facilitating reproducible and therefore transparent work in this field.
keywords:
  formatted: [electronic health records, computational physiology, critical care medicine]
  plain:     [electronic health records, computational physiology, critical care medicine]
preamble: >
  \usepackage{amsmath}
  \usepackage{booktabs}
  \usepackage{makecell}
  \usepackage{threeparttablex}
  \usepackage{tikz}
  \usepackage{pgf}
  \usetikzlibrary{positioning,shadows,arrows,shapes,shapes.arrows,shapes.geometric,arrows.meta,trees,shapes.misc}
vignette: >
  %\VignetteIndexEntry{Accessing ICU data with R (Bennett & Plečko, JSS 2021)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
output: >
  if (packageVersion("rticles") < 0.5 || rmarkdown::pandoc_version() >= 2)
    rticles::jss_article else rmarkdown::html_vignette
documentclass: jss
classoption: notitle
bibliography: jss.bib
pkgdown:
  as_is: true
  extension: pdf
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(dev = "tikz")

library(ricu)
library(data.table)
library(forestmodel)
library(survival)
library(ggplot2)

options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)
```

\maketitle

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\footnotetext{$^{*}$These authors contributed equally.}
\renewcommand*{\thefootnote}{\arabic{footnote}}

```{r data-avail, echo = FALSE}
srcs  <- c("mimic", "mimic_demo", "eicu", "eicu_demo", "hirid", "aumc")
avail <- is_data_avail(srcs)

srcs_avail <- function(x) all(avail[x])

paste1 <- function(x) {

  x <- paste0("`", x, "`")

  if (length(x) <= 2L) {
    return(paste0(x, collapse = " and "))
  }

  paste0(paste0(head(x, n = length(x) - 2L), collapse = ", "), ", ",
         paste0(tail(x, n = 2L), collapse = " and "))
}

if (!srcs_avail(srcs)) {

  msg <- paste(
    "Note: Examples in this vignette require that datasets",
    paste1(srcs[!avail]), "are available. Chunks that depend on certain",
    "datasets will not be evaluated if the corresponding dataset is missing.",
    "The full version of this vignette is available from",
    "https://CRAN.R-project.org/package=ricu/vignettes/jss.pdf"
  )

  message(paste(strwrap(msg), collapse = "\n"))
}

demo_src_avail <- function(x, msg = FALSE) {

  if (srcs_avail(x)) {
    return(TRUE)
  }

  demo <- paste0(x, "_demo")

  if (srcs_avail(demo)) {

    txt <- paste(
      "Note: The following code chunks are intended to be run using data",
      "from", paste1(x), "which is not available. Alternatively, data from",
      paste1(demo), "is used instead."
    )

    if (msg) {
      message(paste(strwrap(txt), collapse = "\n"))
    }

    TRUE

  } else {

    FALSE
  }
}

only_demo <- function(x, ...) !srcs_avail(x) && demo_src_avail(x, ...)
```

# Introduction

Collection of electronic health records has seen a significant rise in recent years \citep{evans2016}, opening up opportunities and providing the grounds for a large body of data-driven research oriented towards helping clinicians in decision-making and therefore improving patient care and health outcomes \citep{jiang2017}.

One example of a problem that has received much attention from the machine learning community is early prediction of sepsis in ICU \citep{desautels2016, nemati2018, futoma2017, kam2017}. Interestingly, there is evidence that a large proportion of the publications are based on the same dataset \citep{fleuren2019}, the Medical Information Mart for Intensive Care III \citep[MIMIC-III;][]{johnson2016}, which shows a systematic lack of external validation. Part of this problem might well be the need for computational infrastructure handling multiple datasets. The MIMIC-III dataset consists of 26 different tables containing about 20GB of data. While much work and care has gone into data preprocessing in order to provide a self-contained ready -to-use data resource with MIMIC-III, seemingly simple tasks such as computing a sepsis-related organ failure assessment (SOFA) score \citep{vincent1996} remains a non-trivial effort^[There is considerable heterogeneity in number of patients satisfying the Sepsis-3 criterion \citep[of which SOFA provides a major component;][]{singer2016} among studies investigating MIMIC-III. Reported Sepsis-3 prevalence ranges from 11.3% \citep{desautels2016}, over 23.9% \citep{nemati2018} and 25.4% \citep{wang2018}, up to 49.1% \citep{johnson2018}. While some of this variation may be explained by differing patient inclusion criteria, diversity in label implementation must also contribute significantly.]. This is only exacerbated when aiming to co-integrate multiple different datasets of this form, spanning hospitals and even countries, in order to capture effects of differing practice and demographics.

The aim of the [\pkg{ricu}](https://cran.r-project.org/package=ricu) package is to provide computational infrastructure allowing users to investigate complex research questions in the context of critical care medicine as easily as possible by providing a unified interface to a heterogeneous set of data sources. The package enables users to write dataset-agnostic code which can simplify implementation and shorten the time necessary for prototyping code querying different datasets. In its current form, the package handles four large-scale, publicly available intensive care databases out of the box: MIMIC-III from the Beth Israel Deaconess Medical Center in Boston, Massachusetts \citep{johnson2016}, the eICU Collaborative Research Database \citep{pollard2018}, containing data collected from 208 hospitals across the United States, the High Time Resolution ICU Dataset (HiRID) from the Department of Intensive Care Medicine of the Bern University Hospital, Switzerland \citep{faltys2021} and AmsterdamUMCdb from the Amsterdam University Medical Center \citep{thoral2021}. Furthermore, \pkg{ricu} was designed with extensibility in mind such that adding further public and/or private user-provided datasets is possible. Being implemented in \proglang{R}, a programming language popular among statisticians and data analysts, it is our hope to contribute to accessible and reproducible research by using a familiar environment and requiring only few system dependencies, thereby simplifying setup considerably.

To our knowledge, infrastructure that provides a common interface to multiple such datasets is a novel contribution. While there have been efforts \citep{adibuzzaman2016, wang2020} attempting to abstract away some specifics of a dataset, these have so far exclusively focused on MIMIC-III, the most popular of public ICU datsets and have not been designed with dataset interoperability in mind.

Given the somewhat narrow focus of the targeted datasets, combined with the fact that in some cases data is even extracted from identical patient care management systems, it may come as a surprise as to how heterogeneous the resulting datasets are. In MIMIC-III and HiRID, for example, time-stamps are reported as absolute times (albeit randomly shifted due to data privacy concerns), whereas eICU and AUMC use relative times (with origins being admission times). Another example, involves different types of patient identifiers and their use among datasets. Common to all is the notion of an ICU admission ID, but apart from that, the amount of available information varies: While ICU (and hospital) readmissions for a given patient can be identified in some, this is not possible in other datasets. Furthermore, use of identifier systems might not be consistent over tables. In MIMIC-III, for example, some tables refer to ICU stay IDs while others use hospital stay IDs, which slightly complicates data retrieval for a given ID system. Additionally, table layouts vary (*long* versus *wide* data arrangement) and data organization in general is far from consistent over datasets.

# Quick start guide

The following list gives a quick outline of the steps required for setting up and starting to use \pkg{ricu}, alongside some section references on where to find further details. A more comprehensive version of this overview is available as a [separate vignette](https://CRAN.R-project.org/package=ricu/vignettes/ricu.html).

1. Package installation:

    * the latest release of \pkg{ricu} can be installed from CRAN as `install.packages("ricu")`

    * alternatively, the latest development version is available from [Github](https://github.com/eth-mds/ricu) by running `remotes::install_github("eth-mds/ricu")`

1. Requesting access to datasets and data source setup:

    * demo datasets can be set up by installing the data packages `mimic.demo` and/or `eicu.demo`, passing `"https://eth-mds.github.io/physionet-demo"` as `repos` argument to `install.packages()`

    * the complete MIMIC-III, eICU and HiRID datasets can be accessed by setting up an account at [PhysioNet](https://physionet.org/register)

    * access to AUMCdb is available via the [Amsterdam Medical Data Science Website](https://amsterdammedicaldatascience.nl/#amsterdamumcdb)

    * the obtained credentials can be configured for PhysioNet datasets by setting environment variables `RICU_PHYSIONET_USER` and `RICU_PHYSIONET_PASS`, while the download token for AUMCdb can be set as `RICU_AUMC_TOKEN`

    * datasets are downloaded and set up either automatically upon the first access attempt or manually by running `setup_data_src()`; the environment variable `RICU_DATA_PATH` can be set to control data location

    * dataset availability can be queried by calling `src_data_avail()`

    A more detailed description of the datasets and the setup process is given in Section \ref{data-sources}, with Section \ref{ready-to-use-datasets} providing an overview of each of the 4 supported datasets and Section \ref{implementation-details} elaborating on how datasets are represented in code.

1. Loading of data corresponding to clinical concepts using `load_concepts()`:

    * currently, over 100 data concepts are available for the 4 supported datasets (see `concept_availability()`/`explain_dictionary()` for names, availability etc.)

    * both concepts and data sources can be specified as strings; for example, glucose and age data can be loaded from MIMIC-III as `load_concepts(c("age", "glu"), "mimic")`

    Section \ref{data-concepts} goes into more detail on how data concepts are represented within \pkg{ricu} and an overview of the pre-configured concepts is available from Section \ref{clinical-concepts}.

1. Extending the concept dictionary:

    * data concepts can be specified in code using the constructors `concept()`/`item()` or `new_concept()`/`new_item()`

    * for session persistence, data concepts can also be specified as JSON formatted objects

    * JSON-based concept dictionaries can either extend or replace others and they can be pointed to by setting the environment variable `RICU_CONFIG_PATH`

    The JSON format used to encode data concepts is discussed in more detail in Section \ref{concept-specification}.

1. Adding new datasets:

    * a JSON-based dataset configuration file is required, from which the configuration objects described in Section \ref{implementation-details} are created

    * in order for concepts to be available from the new dataset, the dictionary requires extension by adding new data items

    Some further information about adding a custom dataset is available from Section \ref{adding-external-datasets}, albeit not in much detail. Some code used when AUMCdb was not yet fully integrated with \pkg{ricu} is available from [Github](https://github.com/eth-mds/aumc).

The final section (\ref{examples}) shows briefly how \pkg{ricu} could be used in practice to address clinical questions by presenting two small examples.

# Data sources

In order to make data available from different data sources, \pkg{ricu} provides abstractions using JSON-formatted configuration files and a set of S3 classes with associated S3 generic functions. This system is designed with extensibility in mind, allowing for incorporation of external datasets that are sufficiently similar in format to the ones already included. Provisions for several large-scale publicly available datasets in terms of required configuration information alongside class-specific implementations of the needed S3 generic functions are part of \pkg{ricu}, opening up access to these datasets. Data itself, however, is not part of \pkg{ricu} but rather can be downloaded from the Internet using tools provided by \pkg{ricu}. While the datasets are publicly available, access has to be granted by the dataset creators individually. Three datasets, MIMIC-III, eICU and HiRID are hosted on PhysioNet \citep{goldberger2000}, access to which requires an [account](https://physionet.org/register/). The fourth dataset, AmsterdamUMCdb, is currently distributed via a separate platform, requiring a [download link](https://amsterdammedicaldatascience.nl/#amsterdamumcdb).

For both MIMIC-III and eICU, small subsets of data are available as demo datasets that do not require credentialed access to PhysioNet. As the terms for distribution of these demo datasets are less restrictive, they can be made available as data packages \pkg{mimic.demo} and \pkg{eicu.demo}. Due to size constraints, however they are not available via CRAN, but can be installed from Github as

```{r demo-data, eval = FALSE}
install.packages(
  c("mimic.demo", "eicu.demo"),
  repos = "https://eth-mds.github.io/physionet-demo"
)
```

Provisions for datasets configured to be attached during package loading are made irrespective of whether data is actually available. Upon access of an incomplete dataset, the user is asked for permission to download in interactive sessions and an error is thrown otherwise. Credentials can either be provided as environment variables (`RICU_PHYSIONET_USER` and `RICU_PHYSIONET_PASS` for access to PhysioNet data, as well as `RICU_AUMC_TOKEN` for AmsterdamUMCdb) and if the corresponding variables are unset, user input is again required in interactive sessions. For non-interactive sessions, functionality is exported such that data can be downloaded and set up ahead of first access (see `?setup_src_data`).

## Ready to use datasets

Contingent on being granted access by the data owners, several large-scale ICU datasets collected from multiple hospitals in the US and Europe can be set up for access using \pkg{ricu} with minimal user effort. Download requires a stable Internet connection, as well as 50 to 100 GB of temporary disk storage for unpacking and preparing the data for efficient access. In terms of permanent storage, 5 to 10 GB per dataset are required, while memory requirements permit importing (and working with) even the largest tables using Laptop class hardware as only subsets of rows are read at once.

The following paragraphs serve to give quick introductions to the included datasets to offer some guidance, outlining some strengths and weaknesses of each of the datasets. Especially the PhysioNet datasets [MIMIC-III](https://mimic.physionet.org/about/mimic/) and [eICU](https://eicu-crd.mit.edu/about/eicu/) offer good documentation on the respective websites. This section is concluded with a table summarizing similarities and differences among the datasets, outlined in the following paragraphs (see Table \ref{tab:datasets}).

### MIMIC-III

The [Medical Information Mart for Intensive Care III (MIMIC-III)](https://physionet.org/content/mimiciii/1.4/) represents the third iteration of the arguably most influential initiative for collecting and providing to the public large-scale ICU data^[The initial MIMIC (at the time short for Multi-parameter Intelligent Monitoring for Intensive Care) data release dates back 20 years and contained data on roughly 100 patients recorded from patient monitors in the medical, surgical, and cardiac intensive care units of Boston's Beth Israel Hospital during the years 1992-1999 \citep{moody1996}. Significantly broadened in scope, MIMIC-II was released 10 years after, now including data on almost 27,000 adult hospital admissions collected from ICUs of Beth Israel Deaconess Medical Center (BIDMC) from 2001 to 2008 \citep{lee2011}. Following MIMIC-III, release of MIMIC-IV is imminent with a first development version having been released in summer 2020. This iteration of MIMIC too is planned to be included with \pkg{ricu} as soon a first stable version is released.]. The dataset comprises de-identified health related data of roughly 46,000 patients admitted to critical care units of BIDMC during the years 2001-2012. Amounting to just over 61,000 individual ICU admission, data is available on demographics, routine vital sign measurements (at approximately 1 hour resolution), laboratory tests, medication, as well as critical care procedures, organized as a 26-table relational structure.

```{r mimic-tbls, eval = srcs_avail("mimic"), include = srcs_avail("mimic")}
mimic
```

```{r mimic_demo-tbls-eval, echo = FALSE}
eval_next <- only_demo("mimic", TRUE)
```

```{r mimic_demo-tbls, eval = eval_next, include = eval_next}
mimic_demo
```

One thing of note from a data-organizational perspective is that a change in electronic health care systems occurred in 2008. Owing to this, roughly 48,000 ICU admissions spanning the years 2001 though 2008 are documented using the CareVue system, while for 2008 and onwards, data was extracted from the MetaVision system. Item identifiers differ between the two systems, requiring queries to consider both ID mappings (heart rate for example being available both as `itemid` number `211` for CareVue and `220045` for MetaVision) as does documentation of infusions and other procedures that are considered as input events (c.f. `inputevents_cv` and `inputevents_mv` tables). Especially with respect to such input event data, MetaVision data generally is of superior quality.

In terms of patient identifiers, MIMIC-III allows for identifying both individual patients (`subject_id`) across hospital admissions (`hadm_id`) and for connecting ICU (re-)admissions (`icustay_id`) to hospital admissions. Using the respective one-to-many relationships, \pkg{ricu} can retrieve patient data using any of the above IDs, irrespective of how the raw data is organized.

### eICU

Unlike the single-center focus of other datasets, the [eICU Collaborative Research Database](https://physionet.org/content/eicu-crd/2.0/) constitutes an amalgamation of data from critical care units of over 200 hospitals throughout the continental United States. Large-scale data collected via the Philips eICU program which provides telehealth infrastructure for intensive care units, is available from the Philips eICU Research Institute (eRI), albeit neither publicly nor freely. Only data corresponding to roughly 200,000 ICU admissions, sampled from a larger population of over 3 million ICU admissions and stratified by hospital, is being made available via PhysioNet. Patients with discharge dates in 2014 or 2015 were considered, with stays in low acuity units being removed.

```{r eicu-tbls, eval = srcs_avail("eicu"), include = srcs_avail("eicu")}
eicu
```

```{r eicu_demo-tbls-eval, echo = FALSE}
eval_next <- only_demo("eicu", TRUE)
```

```{r eicu_demo-tbls, eval = eval_next, include = eval_next}
eicu_demo
```

The data is organized into 31 tables and includes patient demographics, routine vital signs, laboratory measurements, medication administrations, admission diagnoses, as well as treatment information. Owing to the wide range of hospitals participating in this data collection initiative, spanning small, rural, non-teaching health centers with fewer than 100 beds to large teaching hospitals with an excess of 500 beds, data availability varies. Even if data was being recorded at the bedside it might end up missing from the eICU dataset due to technical limitations of the collection process. As for patient identifiers, while it is possible to link ICU admissions corresponding to the same hospital stay, it is not possible to identify patients across hospital stays.

Data resolution again varies considerably over included variables. The `vitalperiodic` table stands out as one of the few examples of a *wide* table organization (laying out variables as columns), as opposed to the *long* presentation (following an entity–attribute–value) of most other tables containing patient measurement data. The average time step in `vitalperiodic` is around 5 minutes, but data missingness ranges from around 1% for heart rate and pulse oximetry to around 80-90% for blood pressure measurements, therefore giving approximately hourly resolution for such variables.

### HiRID

Developed for early prediction of circulatory failure \citep{hyland2020}, the [High Time Resolution ICU Dataset (HiRID)](https://physionet.org/content/hirid/1.0/) contains data on almost 34,000 admissions to the Department of Intensive Care Medicine of the Bern University Hospital, Switzerland, an interdisciplinary 60-bed unit. Given the clear focus on a concrete application during data collection, this dataset is the most limited in terms of breadth of available information, which is also reflected in a comparatively simple data layout comprising only 5 tables^[The data is available in three states: as raw data and in preprocessed form, with preprocessed data being represented by two intermediary pipeline stages from \citep{hyland2020}. While \pkg{ricu} focuses exclusively on raw data, the *merged* stage represents a selection of variables that were deemed most predictive for determining circulatory failure, which are then merged into 18 meta-variables, representing different clinical concepts. Time stamps in *merged* data are left unchanged, yielding irregular time series, whereas for the *imputed* stage, data is down-sampled to a 5 minute grid and missing values are imputed using a scheme discussed in \citep{hyland2020}.].

```{r hirid-tbls, eval = srcs_avail("hirid")}
hirid
```

Collected during the period of January 2008 through June 2016, roughly 700 distinct variables covering routine vital signs, diagnostic test results and treatment parameters are available with variables monitored at the bedside being recorded with two minute time resolution. In terms of demographic information and patient identifier systems however, the data is limited. It is not possible to identify ICU admissions corresponding to individual patients and apart from patient age, sex, weight and height, very little information is available to characterize patients. There is no medical history, no admission diagnoses, only in-ICU mortality information, no unstructured patient data and no information on patient discharge. Furthermore, data on body fluid sampling has been omitted, complicating for example the construction of a Sepsis-3 label \citep{singer2016}.

### AmsterdamUMCdb

As a second European dataset, also focusing on increased time-resolution over the US datasets, [AmsterdamUMCdb](https://amsterdammedicaldatascience.nl/#amsterdamumcdb) has been made available in late 2019, containing data on over 23,000 intensive care unit and high dependency unit admissions of adult patients during the years 2003 through 2016. The department of Intensive Care at Amsterdam University Medical Center is a mixed medical-surgical ICU with up to 32 bed ICU and 12 bed high dependency units with an average of 1000-2000 yearly admissions. Covering middle ground between the US datasets and HiRID in terms of breadth of included data, while providing a maximal time-resolution of 1 minute, AmsterdamUMCdb constitutes a well organized high quality ICU data resource organized succinctly as a 7-table relational structure.

```{r aumc-tbls, eval = srcs_avail("aumc")}
aumc
```

A slightly different approach to data anonymization was chosen for this dataset, yielding demographic information such as patient weight, height and age only available as binned variables instead of raw numeric values. Apart from this, there is information on patient origin, mortality, admission diagnoses, as well as numerical measurements including vital parameters, lab results, outputs from drains and catheters, information on administered medication, and other medical procedures. In terms of patient identifiers, it is possible to link ICU admissions corresponding to the same individual, but it is not possible to identify separate hospital admissions.

```{r src-overview-eval, echo = FALSE}
eval_next <- srcs_avail(c("mimic", "eicu", "hirid", "aumc")) ||
  demo_src_avail(c("mimic", "eicu"), msg = TRUE)
```

```{r src-overview, eval = eval_next, echo = FALSE, results = "asis"}
as_quant <- function(x) {

  if (identical(length(x), 0L)) {
    return("-")
  }

  if (is_id_tbl(x)) {
    x <- data_col(x)
  }

  res <- format_2(quantile(x, probs = seq(0.25, 0.75, 0.25), na.rm = TRUE))

  linebreak(paste0(res[2L], "\n(", res[1L], " - ", res[3L], ")"))
}

big_mark <- function(x) {

  if (identical(length(x), 0L)) {
    return("-")
  }

  formatC(x, big.mark = ",", format = "d")
}

format_2 <- function(x) {
  formatC(x, digits = 2L, format = "f")
}

summarize <- function(src, avail) {

  ids <- as_id_cfg(src)
  cnc <- avail[, src]

  los_icu <- load_concepts("los_icu", src, verbose = FALSE)

  hosp_len <- if ("hadm" %in% names(ids)) {
    load_concepts("los_hosp", src, id_type = "hadm", verbose = FALSE)
  }

  sex <- if ("patient" %in% names(ids)) {
    load_concepts("sex", src, id_type = "patient", verbose = FALSE)
  }

  fil <- list.files(src_data_dir(src), recursive = TRUE, full.names = TRUE)
  siz <- sum(vapply(fil, file.size, numeric(1L))) * 1e-9

  vit <- load_concepts("hr", src, interval = mins(1L), verbose = FALSE)
  vit <- vit[, 1 / diff(as.double(get(index_var(vit)), units = "hours")),
             by = c(id_var(vit))]

  lab <- load_concepts("bili", src, interval = mins(1L), verbose = FALSE)
  lab <- lab[, 1 / diff(as.double(get(index_var(lab)), units = "hours")),
             by = c(id_var(lab))]

  c(`Number of tables` = big_mark(length(as_src_env(src))),
    `Disk storage [GB]` = format_2(siz),
    `Available concepts` = sum(cnc),
    `ICU` = big_mark(nrow(los_icu)),
    `Hospital` = big_mark(nrow(hosp_len)),
    `Unique patients` = big_mark(nrow(sex)),
    `ICU stays` = as_quant(los_icu),
    `Hospital stays` = as_quant(hosp_len),
    `Vital signs\n(heart rate)` = as_quant(vit),
    `Lab tests\n(bilirubin)` = as_quant(lab)
  )
}
# if (srcs_avail(c("mimic", "eicu", "hirid", "aumc"))) {
#   srcs <- c("MIMIC", "eICU", "HiRID", "AUMC")
# } else {
#   srcs <- c("MIMIC (demo)", "eICU (demo)")
# }
srcs <- c("MIMIC (demo)", "eICU (demo)")
dict <- load_dictionary(sub(" \\(demo\\)$", "_demo", tolower(srcs)))
avai <- concept_availability(dict, include_rec = FALSE)
summ <- vapply(sub(" \\(demo\\)$", "_demo", tolower(srcs)), summarize,
               character(10L), avai)

colnames(summ)     <- srcs
rownames(summ)     <- linebreak(rownames(summ), align = "l")
rownames(summ)[3L] <- paste0(rownames(summ)[3L],
                             footnote_marker_symbol(1, "latex"))

n_rec_cpt <- nrow(concept_availability(dict, include_rec = TRUE)) -
             nrow(avai)

capt <- paste(
  "Comparison of datasets supported by \\pkg{ricu}, highlighting some of",
  "the major similarities and distinguishing features among the four data",
  "sources described in the preceding paragraphs. Values followed by",
  "parenthesized ranges represent medians and are accompanied by quartiles."
)

tbl <- kable(summ, format = "latex", escape = FALSE, booktabs = TRUE,
             caption = capt, label = "datasets")
tbl <- pack_rows(tbl, "Admission counts", 4, 6)
tbl <- pack_rows(tbl, "Stay lengths [days]", 7, 8)
tbl <- pack_rows(tbl, "Frequency [1/hour]", 9, 10)
tbl <- footnote(tbl, symbol = paste(
  "These values represent the number of atomic concepts per data source.",
  "Additionally,", n_rec_cpt, "recursive concepts are available, which",
  "build on source-specific atomic concepts in a source-agnostic manner",
  "(see Section \\\\ref{concept-specification} for details)."),
  threeparttable = TRUE, escape = FALSE
)
tbl
```

## Implementation details and external datasets

In this subsection we cover the implementation details of the \pkg{ricu} package and along the way explain which components of the implementation are required for adding an external dataset. Throughout the subsection, we make use of the graphical representation in Figure \ref{fig:infrastructure}, which represents some of the key steps necessary to load and preprocess the data. Each arrow in the figure represents a distinct step in the loading process and we discuss these steps in order. Above the arrow are indicated the functions which are used for each step, whereas below the arrow are indicated specific configuration settings or environment variables which are need for the specific step (in red).

\begin{figure}
	\centering
	\begin{tikzpicture}[
	  every node/.style={draw=none, align=center, fill=none, text centered, anchor=center,font=\it},
	  every label/.style={circle, draw, fill = yellow},
	  f1/.style={draw=,fill=gray!15,thick,inner sep=3pt,minimum width=10em, minimum height=4em, align=center, text centered},
	  f2/.style={draw=none,fill=red!15,thick,inner sep=3pt,minimum width=5em,  align=center, text centered}
	]

	\node [f1, label={above left:{a}}] (ricu) at (0, 19) {\texttt{ricu} installed\\ no data};
		\node [f1, label={above left:{b}}] (csv) at (10, 19) {unconverted tables\\ (.tar or .csv)};
		\node [f1, label={above left:{c}}] (raw) at (0, 12) {raw tables\\ (.fst)};
		% Refined Observational
		\node [f1, label={above left:{d}}] (inmem) at (10, 12) {in-memory table\\
		 (data.table)};
		\node [f1, label={above left:{e}}] (reltime) at (0, 5) {in-memory table\\ relative timestamps\\ minute resolution};
		\node [f1, label={above left:{f}}] (requestID) at (10, 5) {in-memory table\\ desired time stamps\\ requested ID system};

		\draw [-Stealth] (ricu) to [bend right = 0] node[above, rotate=0]{\texttt{download\_src()} / manual} node[f2, below, rotate=0]{\texttt{RICU\_PHYSIONET\_USER}\\\texttt{RICU\_PHYSIONET\_PASS} \\ \texttt{RICU\_AUMC\_TOKEN}} (csv);
		\draw [-Stealth] (csv) to [bend right = 0] node[above, rotate=35]{\texttt{import\_src()}} node[f2, below, rotate=35]{table config} (raw);
		\draw [-Stealth] (raw) to [bend right = 0] node[above, rotate=0]{\texttt{subset()} / \texttt{load\_src()}} (inmem);
		\draw [-Stealth] (inmem) to [bend left = 0] node[above, rotate=35]{\texttt{load\_difftime()}} node[f2, below, rotate=35]{\texttt{load\_difftime()} method\\ ID config, column config} (reltime);
		\draw [-Stealth] (reltime) to [bend right = 0] node[above, rotate=0]{\texttt{load\_id()} / \texttt{load\_ts()}} node[f2, below, rotate=0]{ID conversion} (requestID);

	\end{tikzpicture}
	\caption{A graphical representation of the data-processing infrastructure of the \pkg{ricu} package.}
	\label{fig:infrastructure}
\end{figure}

\subsubsection{Data download} \label{loading:download}
The first step towards loading data is data download. For the datasets included in \pkg{ricu}, the S3 generic `download_src()` can be used. Prior to using the function, the following environment variables need to be set:

* `RICU_PHYSIONET_USER`/`RICU_PHYSIONET_PASS`: PhysioNet user name and password with access to the requested dataset.
* `RICU_AUMC_TOKEN`: Download token, extracted from the download URL received when requesting data access.
If above mentioned access credentials are not available as environment variables, the user is queried in interactive sessions.

If the user is interested in adding an external dataset, then the data download step should be done manually. The environment variable `RICU_DATA_PATH` contains the data storage location {\color{red} Drago: Not sure this is true. For me this environment variable is empty... does that mean it is only used for overriding the default?} (can also be queried by calling `data_dir()`), in which a folder with the dataset name should be created and raw files placed within. This environment variable can be customized by the user.

Each of the supported \pkg{ricu} datasets requires 5-10 GB disk space for permanent storage. Additionally, 50-100 GB of temporary disk storage is required during download and import of any of the datasets. Memory requirements are kept low by performing all set-up operations only on subsets of rows at the time, such that 8 GB of memory should suffice. Initial data source set up (depending on available download speeds and CPU/disk type) may take upwards of an hour per dataset.

\subsubsection{Data import} \label{loading:import}
After successful data download, importing prepares tables for efficient random row-access, for which the raw data format (.csv) is not well suited. For the import step, the S3 generic `import_src()` is used. Tables are read in using \pkg{readr} \citep{hester2020}, potentially (re-)partitioned row-wise, and re-saved using \pkg{fst}. Finally, attaching a dataset (using `attach_src()`) creates a corresponding `src_env` object, which, together with associated meta-data, is used by \pkg{ricu} to run queries against the data. Here it is worth mentioning another two environment variables that play an important role in data import and setup:

* `RICU_CONFIG_PATH`: Comma-separated paths to directories containing configuration files (in addition to the default location; retrievable using `config_paths()`).
* `RICU_SRC_LOAD`: Comma-separated data source names that are set up for being automatically attached on namespace loading (the current set of data sources is available as `auto_attach_srcs()`).

Data source environments (and corresponding `src_tbl` objects) are constructed using source configuration objects: list-based structures, inheriting from `src_cfg` and from any number of data source-specific class names with suffix `_cfg` appended. The exported function `load_src_cfg()` reads a JSON formatted file using \pkg{jsonlite} \citep{ooms2014}, and creates a `src_cfg` object per datasource and further therein contained objects.

```{r mimic-cfg}
cfg <- load_src_cfg("mimic_demo")
str(cfg, max.level = 2L, width = 70L)
mi_cfg <- cfg[["mimic_demo"]]
```

In addition to required fields `name` and `prefix` (used as class prefix), as well as further arbitrary fields (`url` in this case), several additional configuration objects are part of `src_cfg`: `id_cfg`, `col_cfg` and `tbl_cfg`. At the import stage, the `tbl_cfg` object plays an important role, which we now explain.

#### Table configuration

Objects of type `tbl_cfg` are used during the initial set-up of a data source. In order to create a representation of a table that is accessible from \pkg{ricu} from raw data, several key pieces of information are required:

* File name(s): In the simplest case, a single file corresponds to a single table. Other scenarios that have been encountered (and are therefore handled) include tables partitioned into multiple files and .tar archives containing multiple tables.

* Column specification: For each column, the expected data type has to be known, as well as a pair of names, one corresponding to the raw data column name and one corresponding to the column name to be used within \pkg{ricu}.

* (Optional) number of rows: Used as sanity check whenever available.

* (Optional) partitioning information: For very *long* tables it can be useful to specify a row-partitioning. This currently is only possible by applying a vector of breakpoints to a single numeric column, thereby defining a grouping.

```{r mimic-tbl}
as_tbl_cfg(mi_cfg)
```

For the `chartevents` table of the MIMIC-III demo dataset, for example, rows are partitioned into two groups, while all other tables are represented by a single partition. Furthermore, the expected number of rows is unknown (`??`) as this is missing from the corresponding `tbl_cfg` object.
For an external dataset, the table configurations of all tables are needed for the import step (indicated in red in the $b \to c$ edge in Figure \ref{fig:infrastructure}). These table configurations need to be specified in the JSON file `data-sources.json` which is located at `RICU_CONFIG_PATH`. An example of what an entry would look like, for the `admissions` table of the AUMC database is
```{}
"admissions": {
        "files": "admissions.csv",
        "defaults": {
          "index_var": "admittedat",
          "time_vars": ["admittedat", "dischargedat", "dateofdeath"]
        },
        "num_rows": 23106,
        "cols": {
          "patientid": {
            "name": "patientid",
            "spec": "col_integer"
          },
          "admissionid": {
            "name": "admissionid",
            "spec": "col_integer"
          },
          "admissioncount": {
            "name": "admissioncount",
            "spec": "col_integer"
          },
          "location": {
            "name": "location",
            "spec": "col_character"
          },
          ...
}
```
For inspecting the full configuration file, we invite the reader to have a look at our repository for adding an [external dataset](https://github.com/eth-mds/aumc). 

Once the import step is successfully finished, each dataset is represented by an environment with class attributes and associated metadata objects stored as object attributes to that environment. Dataset environments all inherit from `src_env` and from any number of class names constructed from data source name(s) with a suffix `_env` attached. The environment representing MIMIC-III, for example inherits from `src_env` and `mimic_env`, while the corresponding demo dataset inherits from `src_env`, `mimic_env` and `mimic_demo_env`. These sub-classes are later used for tailoring the process of data loading to particularities of individual datasets.

A `src_env` contains an active binding per contained table, which returns a `src_tbl` object representing the requested table. As is the case for `src_env` objects, `src_tbl` objects inherit from additional classes such that certain per-dataset behavior can be customized. The `admissions` table of the MIMIC-III demo dataset for example inherits from `mimic_demo_tbl` and `mimic_tbl` (alongside classes `src_tbl` and `prt`).

```{r mimic-adm, eval = srcs_avail("mimic_demo")}
mimic_demo$admissions
```

\subsubsection{Data loading} \label{loading:basic}

Powered by the \pkg{prt} \citep{bennett2021} package, `src_tbl` objects represent row-partitioned tabular data stored as multiple binary files created by the \pkg{fst} \citep{klik2020} package. In addition to standard subsetting, `prt` objects can be subsetted via the base R S3 generic function `subset()` and using non-standard evaluation:

```{r mimic-sub, eval = srcs_avail("mimic_demo")}
subset(mimic_demo$admissions, subject_id > 44000, language:ethnicity)
```

This syntax makes it possible to read row-subsets of *long* tables into memory with little memory overhead. While terseness of such an API does introduce potential ambiguity, this is mostly overcome by using the tidy eval framework provided by \pkg{rlang} \citep{wickham2020}:

```{r mimic-tidy, eval = srcs_avail("mimic_demo")}
subject_id <- 44000:45000
subset(mimic_demo$admissions, .data$subject_id %in% .env$subject_id,
       subject_id:dischtime)
```

By using \pkg{rlang} pronouns (`.data` and `.env`), the distinction can readily be made between a name referring to an object within the context of the data and an object within the context of the calling environment.

The lowest level of data access is direct subsetting of `src_tbl` objects as shown above. Building on that, several S3 generic functions successively homogenize data representations, starting with `load_src()`, which provides a string-based interface to `subset()` for all but the row-subsetting expression.

```{r load-src, eval = srcs_avail("mimic_demo")}
load_src("admissions", "mimic_demo", subject_id > 44000,
         cols = c("hadm_id", "admittime", "dischtime"))
```

\subsubsection{Data loading - relative times in minutes} \label{loading:relative}

As data sources differ in their representation of time-stamps, a next step in data homogenization is to converge to a common format: the time difference to the origin time-point of a given ID system (by an ID system we refer to a set of identifiers of patient ICU stays, or patient hospital stays; to be discussed shortly). For doing so, the S3 generic `load_difftime()` is used.

```{r load-dt, eval = srcs_avail("mimic_demo")}
load_difftime("admissions", "mimic_demo", subject_id > 44000,
              cols = c("hadm_id", "admittime", "dischtime"))
```

```{r load-dt-print, eval = srcs_avail("mimic_demo"), echo = FALSE}
load_difftime("admissions", "mimic_demo", subject_id > 44000,
              cols = c("hadm_id", "admittime", "dischtime"))[]
```
The function `load_difftime()` is expected to return timestamps as base R `difftime` vectors (using `mins` as time unit). The argument `id_hint` can be used to specify a preferred ID system, but if not available in raw data, `load_difftime()` will return data using the ID system with highest cardinality. In the above example, if `icustay_id` were requested, data would be returned using `hadm_id`, whereas a `subject_id` request would be honored, as these two ID columns are available for the `admissions` table.

When adding an external dataset, note that a method for the `load_difftime()` needs to be added. Furthermore, an ID configuration specification and a default column configuration specification and are necessary. We now explain what the two entail.

#### ID configuration

An `id_cfg` object contains an ordered set of key-value pairs representing patient ID systems in a dataset. An implicit assumption currently is that a given patient ID system is used consistently throughout a dataset, meaning that for example an ICU stay ID is always referred to by the same name throughout all tables containing a corresponding column. Owing to the relational origins of these datasets this has been fulfilled in all instances encountered so far. In MIMIC-III demo, ID systems

```{r mimic-ids}
as_id_cfg(mi_cfg)
```

are available, allowing for identification of individual patients, their (potentially multiple) hospital admissions over the course of the years and their corresponding ICU admissions (as well as potential re-admissions). Ordering corresponds to cardinality: moving to larger values implies moving along a one-to-many relationship. This information is used in data-loading, whenever the target ID system is not contained in the raw data. To specify the ID configuration of an external dataset, the appropriate information needs to be included in the `data-sources.json` file. For the AUMCdb, the entry would need to look as follows:
```
"id_cfg": {
      "patient": {
        "id": "patientid",
        "position": 1,
        "start": "firstadmittedat",
        "end": "dateofdeath",
        "table": "admissions"
      },
      "icustay": {
        "id": "admissionid",
        "position": 2,
        "start": "admittedat",
        "end": "dischargedat",
        "table": "admissions"
      }
    }
```
In this dataset, only patients and their ICU stays can be distinguished (it is not possible to distinguish hospital re-admissions).

#### Default column configuration

During data loading, certain columns need to be used, as described above, to identify patient ICU or hospital stays. Another set of columns might encode timestamp information, whereas a third set of columns might contain information on measurement units. Motivated by this, the following column keys are currently in use throughout \pkg{ricu}, but this set of keys can be extended to arbitrary new values:

* `id_var`: A column used to identifu unique ICU stays, hospital stays or patients. In case a table does not contain at least one ID column corresponding to one of the ID systems specified as `id_cfg`, the default ID column can be set on a per-table basis as `id_var`^[This for example is the case for the `d_items` table in MIMIC-III, which does not contain any patient related data, but holds information on items encoding types of measurements, procedures, etc., used throughout other tables holding actual patient data for identifying the type data point, in line with the relational structure of the data source.].
* `index_var`: A column that is used to define an ordering in time over rows, thereby providing a time-series index^[For the MIMIC-III table `inputevents_mv`, one of the four available time variables lends itself to be used as index variable more than the other candidates and therefore is set as default.].
* `time_vars`: Columns which will be treated as time variables (important for converting between ID systems for example), but not necessarily as time-series indices^[In case of the `admissions` table in MIMIC-III for example, a total of five columns are considered to be time variables, none of which stands out as potential `index_var`.].
* `unit_var`: Used in concept loading (more specifically for `num_cncpt` concepts, see Section \ref{concept-specification}) to identify columns that represent unit of measurement information.
* `val_var`: Again used when loading data concepts, this identified a default value variable in a table, representing the column of interest to be used as returned data column. 

This per-table set of key-value pairs specifies column defaults as a `col_cfg` object. Each key describes a type of column with special meaning and the corresponding value specifies said column for a given table.

```{r mimic-col}
as_col_cfg(mi_cfg)
```

While `id_var`, `index_var` and `time_vars` are used to provide sensible defaults to functions used for general data loading, `unit_var`, `val_var`, as well as potential user-defined defaults are only used in concept loading (see Section \ref{clinical-concepts}) and therefore need not be prioritized when integrating new data sources until data concepts have been mapped.

Once again, for an external dataset, this information needs to be specified in the `data-sources.json` file, within a `"defaults"` field for each specific table. In the case of `admissions` table of AUMCdb, it looks as follows:
```{}
"admissions": {
        "files": "admissions.csv",
        "defaults": {
          "index_var": "admittedat",
          "time_vars": ["admittedat", "dischargedat", "dateofdeath"]
        },
        ...
}
```

\subsubsection{Data loading - desired relative times and ID system} \label{loading:desired}
After loading the data with relative times in minute resolution, in the next step we convert times to a user defined interval (default 1 hour) and provide data with the requested ID system. For this purpose, building on `load_difftime()` functionality, `load_id()` (and analogously `load_ts()`) returns an `id_tbl` (or `ts_tbl`) object with the requested ID system (passed as `id_var` argument). This uses raw data IDs if available or calls `change_id()` in order to convert to the desired ID system. Similarly, where `load_difftime()` returns data with fixed time interval of one minute, `load_id()` allows for arbitrary time intervals (using `change_interval()`).

```{r load-id, eval = srcs_avail("mimic_demo")}
load_id("admissions", "mimic_demo", subject_id > 44000,
        cols = c("admittime", "dischtime"), id_var = "hadm_id")
```

```{r load-id-print, eval = srcs_avail("mimic_demo"), echo = FALSE}
load_id("admissions", "mimic_demo", subject_id > 44000,
        cols = c("admittime", "dischtime"), id_var = "hadm_id")[]
```

The call to `change_id()` helper function requires a construction of a table which contains the mapping between different ID systems, together with information about how convert timestamps between these ID systems. We now explain how such an ID conversion table can be constructed.

#### ID conversion
To begin with, we show what the ID conversion table looks like on the MIMIC-III demo dataset. It can be obtained by applying the `id_win_helper()` function:
```{r, eval = srcs_avail("mimic_demo"), include = srcs_avail("mimic_demo")}
id_win_helper(mimic_demo)
```
{\color{red} Drago: I do not get any output here?}
Such a conversion table might be used in various places in the data loading process
For an external dataset, the user needs to write a method for the S3 `id_win_helper()` generic. For sake of brevity, we do not show in full detail how to do it for the AUMC dataset, but rather point to user to the code for [constructing the `id_win_helper()` method](https://github.com/eth-mds/aumc/blob/220776b671f90ddb3a0b795cf6d89292e14d8bdd/r/ricu.R#L60). As the construction of the ID conversion table can be expensive (involving several merge operations of tables with 10^4^-10^5^ rows) and could be used frequently (potentially with every single data request), the resulting table will be internally cached in memory, with session persistence.

## Adding external datasets: a recap

In order to add a new dataset to \pkg{ricu}, several aspects outlined in the previous subsections require consideration. The code for integrating AmsterdamUMCdb as an external dataset is available from [Github](https://github.com/eth-mds/aumc). Even though the `aumc` data source is supported by \pkg{ricu}, the repository serves as a template for integration of new datasets. We now recap the most important components of adding an external dataset, referencing subsections in which they are discussed:

1. Place the raw data in a folder in the location queried by `data_dir()` (see Section \ref{loading:download}),
2. Write a `load_difftime()` class-specific method for the external dataset (see Section \ref{loading:relative}),
3. Construct a `data-sources.json` configuration file, and place it in a folder included in `RICU_CONFIG_PATH`. The file should contain:
    i. Table configuration (see Section \ref{loading:import}),
    ii. ID configuration (see Section \ref{loading:relative}),
    iii. Default column configuration (see Section \ref{loading:desired}),
4. Construct an ID conversion table, by writing a class-specific method for the S3 generic `id_win_helper()` (see Section \ref{loading:desired}).

# Data concepts

One of the key components of \pkg{ricu} is a scheme for specifying how to retrieve data corresponding to pre-defined clinical concepts from a given data source, in turn enabling dataset agnostic code for analysis. Heart rate, for example can be loaded using the `hr` concept as

```{r, eval = srcs_avail(c("mimic_demo", "eicu_demo"))}
load_concepts("hr", c("mimic_demo", "eicu_demo"), verbose = FALSE)
```

This requires some form of infrastructure for concisely specifying how to retrieve data subsets (Section \ref{concept-specification}), which is both extensible (to new concepts and new datasets) and flexible enough to handle  concept-specific pre-processing. Additionally, \pkg{ricu} has included a dictionary with over 100 concepts implemented for all four supported datasets (where possible; see also Section \ref{clinical-concepts}). A quick remark on terminology before diving into more details on how to specify data concepts: A *concept* corresponds to a clinical variable such as a bilirubin measurement or the ventilation status of a patient, and an *item* encodes how to retrieve data corresponding to a given concept from a data source. A *concept* therefore contains several *items* (zero, one or several are possible per data source).

## Concept specification

Similarly to data source configuration (discussed in Section \ref{data-source-configuration}), concept specification relies on JSON-formatted text files. A default dictionary of concepts is included with \pkg{ricu} containing a selection of commonly used clinical concepts. Several types of concepts exist within \pkg{ricu} and with extensibility in mind, new types can easily be added.

All concepts consist of minimal meta-data including a name, target class (defaults to `ts_tbl`; see Section \ref{data-classes}), an aggregation specification^[Every concept needs a default aggregation method which can be used during data loading to return data that is unique per key (either per `id_vars` group or per combination of `ìd_vars` and `index_var`) otherwise down-stream merging of multiple concepts is ill-defined. The aggregation default can be overridden during loading or as specification of a `rec_cncpt` object. If no aggregation method is explicitly indicated the global default is `first()` for character, `median()` for numeric and `sum()` for logical vectors. For logical data, if a concept of type `lgl_cncpt` is used, the count of `TRUE` values is converted back to logical, thereby providing `any()` type functionality.] and class information (defaults to `num_concept`), as well as optional `description` and `category` information. Adding to that, depending on concept class, further fields can be added. In the case of the most widespread concept type (`num_cncpt`; used to represent numeric data) this is `unit` which encodes one (or several synonymous) unit(s) of measurement, as well as a minimal and maximal plausible values (specified as `min` and `max`). The concept for heart rate data (`hr`) for example can be specified as

```
{
  "hr": {
    "unit": ["bpm", "/min"],
    "min": 0,
    "max": 300,
    "description": "heart rate",
    "category": "routine vital signs",
    "sources": {
      ...
    }
  }
}
```

Meta-data is used during concept loading for data-preprocessing. For numeric concepts, the specified measurement unit is compared to that of the data (if available), with messages being displayed in case of mismatches, while the range of plausible values is used to filter out measurements that fall outside the specified interval. Other types of concepts include categorical concepts (`fct_cncpt`), concept representing binary data (`lgl_cncpt`), as well as recursive concepts (`rec_cncpt`), which build on other *atomic* concepts^[An example for a recursive concept is the PaO~2~/FiO~2~ ratio, used for instance to assess patients with acute respiratory distress syndrome (ARDS) or for sepsis-related organ failure assessment (SOFA) \citep{villar2013, vincent1996}. Given both PaO~2~ and FiO~2~ as individual concepts, the PaO~2~/FiO~2~ ratio is provided by \pkg{ricu} as a recursive concept (`pafi`), requesting the two atomic concepts `pao2` and `fio2` and performing some form of imputation for when at a given time step one or both values are missing.].

Specification of how data can be retrieved from a data source is encoded by data *items*. Lists of data items (associated with data source names) are provided as `sources` element (instead of `...` in the above code block). For the demo datasets corresponding eICU and MIMIC-III, heart rate data retrieval is specified as

```
{
  "eicu_demo": [
    {
      "table": "vitalperiodic",
      "val_var": "heartrate",
      "class": "col_itm"
    }
  ],
  "mimic_demo": [
    {
      "ids": [211, 220045],
      "table": "chartevents",
      "sub_var": "itemid"
    }
  ]
}
```

Analogously to how different types of concepts are used to represent different types of data, different types of items handle different types of data loading. The most common scenario is selecting a subset of rows from a table by matching a set of ID values (`sub_itm`). In the above example, heart rate data in MIMIC-III can be located by searching for ID values 211 and 220045 in column `itemid` of table `chartevents` (heart rate data is stored in *long* format). Conversely, heart rate data in eICU is stored in *wide* format, requiring no row-subsetting. Column `heartrate` of table `vitalperiodic` contains all corresponding data and such data situations are handled by the `col_itm` class. Other item classes include `rgx_itm` where a regular expression is used for selecting rows and `fun_itm` where an arbitrary function can be used for data loading. If a data loading scenario is not covered by these classes, adding further `itm` subclasses is encouraged.

In order to extend the current concept library both to new datasets and new concepts, further JSON files can be incorporated by adding their paths to `RICU_CONFIG_PATH`. Concepts with names that already exist are only used for their `sources` entries, such that `hr` for `new_dataset` can be specified as

```
"hr": {
  "sources": {
    "new_dataset": [
      {
        "ids": 6640,
        "table": "numericitems",
        "sub_var": "itemid"
      }
    ]
  }
}
```

whereas concepts with non-existing names are treated as new concepts.

Central to providing the required flexibility for loading of certain data concepts that require some specific pre-processing are callback functions that can be specified for several *item* types. Functions (with appropriate signatures), designated as `callback` functions, are invoked on individual data items, before concept-related preprocessing is applied. A common scenario for this is unit of measurement conversion: In MIMIC-III data for example, several `itemid` values correspond to temperature measurements, some of which refer to temperatures measured in degrees Celsius whereas others are used for measurements in degrees Fahrenheit. As the information encoding which measurement corresponds to which `itemid` values is no longer available during concept-related preprocessing, this is best resolved at the level of individual data items. Several function factories are available for generating callback functions and `convert_unit()` is intended for covering unit conversions. Data *items* corresponding to the `temp` concept for MIMIC-III are specified as

```
{
  "mimic_demo": [
    {
      "ids": [676, 677, 223762],
      "table": "chartevents",
      "sub_var": "itemid"
    },
    {
      "ids": [678, 679, 223761, 224027],
      "table": "chartevents",
      "sub_var": "itemid",
      "callback": "convert_unit(fahr_to_cels, 'C', 'f')"
    }
  ]
}
```

indicating that for ID values 676, 677 and 223762 no pre-processing is required and for the remaining ID values the function `fahr_to_cels()` is applied to entries of the `val_var` column where the regular expression `"f"` is `TRUE` for the `unit_var` column (the values of which being ultimately replaced with `"C"`).

## Data classes

In order to represent tabular ICU data, \pkg{ricu} provides several classes, all inheriting from `data.table`. The most basic of which, `id_tbl`, marks one (or several) columns as `id_vars` which serve to define a grouping (i.e. identify patients or unit stays). Inheriting from `id_tbl`, `ts_tbl` is capable of representing grouped time-series data. In addition to `id_var` column(s), a single column is marked as `index_var` and is required to hold a base R `difftime` vector. Furthermore, `ts_tbl` contains a scalar-valued `difftime` object as `interval` attribute, specifying the time-series step size^[As further extension, a `win_tbl` object is being considered for inclusion, capable of representing time intervals. Such an object could prove convenient for example when dealing with infusions as infusion parameters such as medication rate frequently are specified with explicit begin and end times (see Section \ref{treatment-related-information}).].

Meta data is transiently added to `data.table` objects by classes inheriting from `id_tbl` and S3 generic functions which allow for object modifications, down-casting is implicit:

```{r id-tbl}
(dat <- ts_tbl(a = 1:5, b = hours(1:5), c = rnorm(5)))
dat[["b"]] <- dat[["b"]] + mins(30)
dat
```

Due to time-series step size of `dat` being specified as 1 hour, an internal inconsistency is encountered when shifting time stamps by 30 minutes, as time-steps are no longer multiples of the time-series interval, in turn causing down-casting to `id_tbl`. If column `a` were to be removed, direct down-casting to `data.table` would be required in order to resolve inconsistencies^[Updating an object inheriting from `id_tbl` using `data.table::set()` bypasses consistency checks as this is not an S3 generic function and therefore its behavior cannot be tailored to requirements of `id_tbl` objects. It therefore is up to the user to avoid vitiating `id_tbl` objects in such a way.].

Utilizing the attached meta-data, several utility functions can be called with concise semantics. This includes functions for sorting, checking for duplicates, aggregating data per combination of `id_vars` (and time-step), checking time series data for gaps, verifying whether the time-series is regular and converting between irregular and regular time-series, as well as functions for several types of moving window operations. Adding to those class-specific implementations, `id_tbl` objects inherit from `data.table` (and therefore from `data.frame`), ensuring compatibility with a wide range of functionality targeted at these base-classes.

## Clinical concepts

The current selection of clinical concepts that is included with \pkg{ricu} covers many physiological variables that are available throughout the included datasets. Treatment-related information on the other hand, being more heterogeneous in nature and therefore harder to harmonize across datasets, has been added on an as-needed basis and therefore is more limited in breadth.

Available concepts can be enumerated using `load_dictionary()` and the utility function `explain_dictionary()` can be used to display some concept meta-data.

```{r, eval = srcs_avail(c("mimic_demo", "eicu_demo"))}
dict <- load_dictionary(c("mimic_demo", "eicu_demo"))
head(dict)
explain_dictionary(head(dict))
```

The following sub-sections serve to introduce some of the included concepts as well as highlight limitations that come with current implementations. Grouping the available concepts by category yields the following counts

```{r, eval = srcs_avail(c("mimic_demo", "eicu_demo"))}
table(vapply(dict, `[[`, character(1L), "category"))
```

### Physiological data

The largest and most well established group of concepts (covering more than half of all currently included concepts) includes physiological patient measurements such as routine vital signs, respiratory variables, fluid discharge amounts, as well as many kinds of laboratory tests including blood gas measurements, chemical analysis of body fluids and hematology assays.

```{r, eval = srcs_avail("mimic_demo")}
load_concepts(c("alb", "glu"), "mimic_demo", interval = mins(15L),
              verbose = FALSE)
```

Most concepts of this kind are represented by `num_cncpt` objects with an associated unit of measurement and a range of permissible values. Data is mainly returned as `ts_tbl` objects, representing time-dependent observations. Apart from conversion to a common unit (possibly using the `convert_unit()` callback function), little has to be done in terms of pre-processing: values are simply reported at time-points rounded to the requested interval.

### Patient demographics

Moving on from dynamic, time-varying patient data, this group of concepts focuses on static patient information. While the assumption of remaining constant throughout a stay is likely to hold for variables such as patient sex or height this is only approximately true for others including age or weight. Nevertheless such effects are ignored and concepts of this group will be mainly returned as `id_tbl` objects with no corresponding time-stamps included.

Whenever requesting concepts which are returned with associated time-stamps (e.g. glucose) alongside time-constant data (e.g. age), merging will duplicate static data over all time-points.

```{r, eval = srcs_avail("mimic_demo")}
load_concepts(c("age", "glu"), "mimic_demo", verbose = FALSE)
```

Despite a best-effort approach, data availability can be a limiting factor. While for physiological variables, there is good agreement even across continents, data-privacy considerations, as well as lack of a common standard for data encoding, may cause issues that are hard to resolve. In some cases, this can be somewhat mitigated while in others, this is a limitation to be kept in mind. In AmsterdamUMCdb, for example, patient age, height and weight are not available as continuous variables, but as factor with patients binned into groups. Such variables are then approximated by returning the respective mid-points of groups for `aumc` data^[Prioritizing consistency over accuracy, one could apply the same binning to datasets which report numeric values, but the concepts included with \pkg{ricu} attempt to strike a balance between consistency and amount of applied pre-processing. With the extensible architecture of data concepts, however, such categorical variants of patient demographic concepts could easily be added.]. Other concepts, such as `adm` (categorizing admission types) or a prospective `icd` concept (diagnoses as ICD-9 codes) can only return data if available from the data source in question. Unfortunately, neither `aumc` nor `hirid` contain ICD-9 encoded diagnoses, and in the case of `hirid`, no diagnosis information is available at all.

### Treatment-related information

The largest group of concepts dealing with treatment-related information is described by the `medications` category. In addition to drug administrations, only basic ventilation information is currently provided as ready to use concept. Just like availability of common ICU procedures, patient medication is also underdeveloped, covering mainly vasopressor administrations, as well as corticosteroids and antibiotics. The current concepts retrieving treatment-related information are mostly focused on providing data required for constructing clinical scores described in Section \ref{outcomes}.

Ventilation is represented by several concepts: a ventilation indicator variable (`vent_ind`), as well as ventilation durations (`vent_dur`) are constructed from start and events (`vent_start` and `vent_end`). This includes any kind of mechanical ventilation (invasive via an endotracheal or tracheostomy tube), as well as non-invasive ventilation via face or nasal masks. In line with other concepts belonging to this group, the current state is far from being comprehensive and expansion to further ventilation parameters is desirable.

The singular concept addressing antibiotics (`abx`) returns an indicator signaling whenever an antibiotic was administered. This includes any route of administration (intravenous, oral, topical, etc.) and does neither report dosage, nor active ingredient. Finally, vasopressor administration is reported by several concepts representing different vasoactive drugs (including dopamine, dobutamine, epinephrine, noreponephrine and vasopressin), as well as different administration aspects such as rate, duration (and for use in SOFA scoring, rate administered for at least 60 minutes).

```{r, eval = srcs_avail("mimic_demo")}
load_concepts(c("abx", "vent_ind", "norepi_rate", "norepi_dur"),
              "mimic_demo", verbose = FALSE)
```

As cautioned in Section \ref{patient-demographics}, variability in data reporting across datasets can lead to issues: the `prescriptions` table included with MIMIC-III, for example, reports time-stamps as dates only, yielding a discrepancy of up to 24 hours when merged with data where time-accuracy is on the order of minutes. This effect is somewhat mitigated by shifting time-stamps from midnight to mid-day, but the underlying accuracy issue of course remains. Another problem exists with concepts that attempt to report administration windows, as some datasets do not describe infusions with clear cut start/endpoints but rather report infusion parameters at (somewhat) regular time intervals. This can cause artifacts when the requested time step-size deviates from the dataset inherent time grid.

### Outcomes

A group of more loosely associated concepts can be used to describe patient state. This includes common clinical endpoints, such as death or length of ICU stay, as well as scoring systems such as SOFA, the systemic inflammatory response syndrome \citep[SIRS;][]{bone1992} criterion, the National Early Warning Score \citep[NEWS;][]{jones2012} and the Modified Early Warning Score \citep[MEWS;][]{subbe2001}.

While the more straightforward outcomes can be retrieved directly from data, clinical scores often incorporate multiple variables, based upon which a numeric score is constructed. This can typically be achieved by using concepts of type `rec_cncpt`, specifying the needed components and supplying a callback function that applies rules for score construction.

```{r, eval = srcs_avail("mimic_demo")}
load_concepts(c("sirs", "death"), "mimic_demo", verbose = FALSE,
              keep_components = TRUE)
```

Callback functions can become rather involved (especially for more complex concepts such as SOFA) and may include arbitrary arguments to tune their behavior. As callback functions to `rec_cncpt` objects are typically called internally from `load_concepts()`, arguments not used by `load_concepts()`, such as `keep_components` in the above example (causing not only the score column, but also individual score components to be retained) are forwarded^[Some care has to be taken as when requesting multiple concepts within the same call to `load_concepts()` all involved callback functions will be called with the same forwarded arguments. When for example requesting multiple scores, it is currently not possible to enable `keep_components` for only a subset thereof. Furthermore this set-up implies that ].

# Examples

In order to briefly illustrate how \pkg{ricu} could be applied to real-world clinical questions, two toy examples are provided in the following sections. While the first example fully relies on data concepts that are included with \pkg{ricu}, the second one explores both how some data pre-processing can be added to an existing concept by creating a new `rec_cncpt` and how to create an new data concept altogether.

```{r src-sel-eval, echo = FALSE}
eval_next <- srcs_avail("mimic_demo")
```

## Lactate and mortality

First, we investigate the association of lactate levels and mortality. This problem has been studied before and it is widely accepted that both static and dynamic lactate indices are associated with increased mortality \citep{haas2016, nichol2011, van2013}. In order to model this relationship, we fit a time-varying proportional hazards Cox model \citep{therneau2000, therneau2015}, which includes the SOFA score as a general predictor of illness severity, using MIMIC-III demo data. 

<!-- `r if (srcs_avail("mimic")) "Furthermore, for the sake of this example, we are only interested in patients admitted from 2008 onwards of ages 25 to 65 years old."` -->

<!-- ```{r cox-full, eval = srcs_avail("mimic"), include = srcs_avail("mimic")} -->
<!-- src <- "mimic" -->

<!-- cohort <- load_id("icustays", src, dbsource == "metavision", -->
<!--                   cols = NULL) -->
<!-- cohort <- load_concepts("age", src, patient_ids = cohort, -->
<!--                         verbose = FALSE) -->

<!-- dat <- load_concepts(c("lact", "death", "sofa", "sex"), src, -->
<!--                      patient_ids = cohort[age > 25 & age < 65], -->
<!--                      verbose = FALSE) -->
<!-- ``` -->

```{r cox-demo, eval = srcs_avail("mimic_demo"), include = srcs_avail("mimic_demo")}
src <- "mimic_demo"
dat <- load_concepts(c("lact", "death", "sofa", "sex"), src,
                     verbose = FALSE)
```

```{r cox-model, eval = eval_next}
dat <- dat[, head(.SD, n = match(TRUE, death, .N)), by = c(id_vars(dat))]
dat <- fill_gaps(dat)

dat <- replace_na(dat, c(NA, FALSE), type = c("locf", "const"),
                  by_ref = TRUE, vars = c("lact", "death"),
                  by = id_vars(dat))

cox_mod <- coxph(
  Surv(charttime - 1L, charttime, death) ~ lact + sofa,
  data = dat
)
```

After loading the data, some minor pre-processing is still required before modeling: first, we want to make sure we only use data up to (and including) the hour in which the `death` flag switches to `TRUE`. After that we impute missing values for `lact` using a last observation carry forward (locf) scheme (observing the patient grouping) and we simply replace missing `death` values with the value `FALSE`. The resulting model fit can be visualized as:

```{r cox_plot, eval = srcs_avail("mimic_demo"), echo = FALSE, warning = FALSE, message = FALSE, fig.width = 8}
theme_fp <- function(...) {
  theme_bw(...) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.title.y = element_blank(), axis.title.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank())
}

forest_model(cox_mod, theme = theme_fp(16))
```

A simple exploration already shows that the increased values of lactate are associated with mortality, even after adjusting for the SOFA score.

## Diabetes and insulin treatment

For the next example, again using MIMIC-III data, we turn to the usage of co-morbidities and treatment related information. We look at the amount of insulin administered to patients in the first 24 hours from their ICU admission. In particular, we investigate if diabetic patients receive more insulin in the first day of their stay compared to non-diabetic patients. For this we create two concepts: `ins24`, a binned variable representing the cumulative amount of insulin administered within the first 24 hours of an ICU admission, and `diab`, a logical variable encoding diabetes co-morbidity.

As there already is an insulin concept available, `ins24` can be implemented as `rec_cncpt`, loading `ins` with aggregation set to `sum()` (instead of `median()`) and inserting the callback function `ins_cb()` into the loading process. The callback function takes care of the pre-processing steps outlined above: first data is subsetted to fall into the the first 24 hours of ICU admissions, followed by binning of summed values.

```{r ins24, eval = srcs_avail("mimic_demo")}
ins_breaks <- c(0, 1, 10, 20, 40, Inf)

ins_cb <- function(ins, ...) {

  day_one <- function(x) x >= hours(0L) & x <= hours(24L)

  idx_var <- index_var(ins)
  ids_var <- id_vars(ins)

  ins <- ins[
    day_one(get(idx_var)), list(ins24 = sum(ins)), by = c(ids_var)
  ]

  ins <- ins[,
    ins24 := list(cut(ins24, breaks = ins_breaks, right = FALSE))
  ]

  ins
}

ins24 <- load_dictionary(src, "ins")
ins24 <- concept("ins24", ins24, "insulin in first 24h", aggregate = "sum",
                 callback = ins_cb, target = "id_tbl", class = "rec_cncpt")
```

The binary diabetes concept can be implemented as `lgl_cncpt`, for which ICD-9 codes are matched using a regular expression. As we're not only interested in retrieving diabetic patients, a `col_itm` is more suited for data retrieval over an `rgx_itm` and for creating the required callback function that produces a logical vector we can use `transform_fun()` coupled with a function like `grep_diab()`. The two concepts are then combined using `c()` and loaded via `load_concepts()`.

```{r diab, eval = srcs_avail("mimic_demo")}
grep_diab <- function(x) grepl("^250\\.?[0-9]{2}$", x)

diab  <- item(src, table = "diagnoses_icd",
              callback = transform_fun(grep_diab), class = "col_itm")
diab  <- concept("diab", diab, "diabetes", target = "id_tbl",
                 class = "lgl_cncpt")

dat <- load_concepts(c(ins24, diab), id_type = "icustay", verbose = FALSE)
dat <- replace_na(dat, "[0,1)", vars = "ins24")
dat
```

After this, we can visualize the difference between the two groups with a histogram:

```{r diabetes-visualize, echo = FALSE, eval = srcs_avail("mimic_demo"), fig.height = 3}
dat <- dat[, weight := 1 / .N, by = diab]
ggplot(dat, aes(x = ins24, fill = diab)) +
  stat_count(aes(weight = weight), alpha = 0.75, position = "dodge") +
  labs(x = "Amount of administered insulin in first 24h of ICU stay [units]",
       y = "Proportion of patients",
       fill = "Diabetic") +
  theme_bw(10)
```

The plot suggests that during the first day of ICU stay, perhaps unsurprisingly, diabetic patients receive more insulin compared to non-diabetic patients, especially as insulin dose increases.

# Acknowledgments

Nicolas Bennett, Drago Plečko, Nicolai Meinshausen and Peter Bühlmann were supported by grant #2017-110 of the Strategic Focal Area "Personalized Health and Related Technologies (PHRT)" of the ETH Domain for the SPHN/PHRT Driver Project "Personalized Swiss Sepsis Study".

```{r session-info, include = FALSE}
sessionInfo()
```
